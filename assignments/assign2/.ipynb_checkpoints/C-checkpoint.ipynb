{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question C\n",
    "Increase the number of neurons.  Plot the test error of the best trained linear models with increasing number of neurons.  You can experiment with different network sizes.  Plot the test error with respect to the neurons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "%matplotlib inline\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "The test error for the final iteration of the training is: 29.62 percent.\n"
     ]
    }
   ],
   "source": [
    "numPixels = 784\n",
    "firstLayerOutput = 100\n",
    "numClassifications = 10\n",
    "\n",
    "# Initial input\n",
    "x = tf.placeholder(tf.float32, [None, numPixels])\n",
    "# Reference\n",
    "ref = tf.placeholder(tf.float32, [None, numClassifications])\n",
    "\n",
    "logits1 = tf.layers.dense(inputs=x, units=firstLayerOutput, activation=tf.nn.relu, name=\"L1\")\n",
    "logits2 = tf.layers.dense(inputs=logits1, units=numClassifications, activation=tf.nn.relu, name=\"L2\")\n",
    "\n",
    "# First layer\n",
    "\n",
    "# # First weight variable\n",
    "# W1 = tf.Variable(tf.zeros([numPixels, firstLayerOutput]))\n",
    "# # First bias variable\n",
    "# b1 = tf.Variable(tf.zeros([firstLayerOutput]))\n",
    "# # First layer calculation. N x 100 size\n",
    "# logits1 = tf.nn.relu(tf.matmul(x, W1) + b1)\n",
    "\n",
    "# # Second layer\n",
    "\n",
    "# # Second weight variable\n",
    "# W2 = tf.Variable(tf.zeros([firstLayerOutput, numClassifications]))\n",
    "# # Second bias variable\n",
    "# b2 = tf.Variable(tf.zeros([numClassifications]))\n",
    "# # Second layer calculation for the number of classifications. N x 10\n",
    "# logits2 = tf.nn.relu(tf.matmul(logits1, W2) + b2)\n",
    "\n",
    "# Calculate the cross entropy, doing the softmax function internally\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits2, labels=ref)\n",
    "\n",
    "# Take the average of the cross entropy values\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# (N). Take the highest percentile value in the prediction as the answer\n",
    "prediction = tf.argmax(tf.nn.softmax(logits2), axis=1)\n",
    "\n",
    "labels = []\n",
    "for label in mnist.test.labels:\n",
    "    labels.append(np.argmax(label))\n",
    "labels = np.array(labels)\n",
    "\n",
    "rate = 0.1\n",
    "epochs = 1000\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(rate).minimize(cost)\n",
    "s = tf.Session()\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "inputData, correctAns = mnist.train.next_batch(100)\n",
    "validationInput, validationCorrect = mnist.train.next_batch(100)\n",
    "\n",
    "for i in range(epochs):\n",
    "    # Do the training\n",
    "    err, _ = s.run((cost, optimizer), feed_dict={x: inputData, ref: correctAns})\n",
    "\n",
    "print(\"DONE\")\n",
    "\n",
    "# Check the test error\n",
    "predic = s.run((prediction), feed_dict={x: mnist.test.images})\n",
    "answers = np.equal(labels, predic)\n",
    "corrGuesses = np.sum(answers)\n",
    "testErr = corrGuesses / len(answers)   \n",
    "print(\"The test error for the final iteration of the training is: \" + str((1 - testErr) * 100) + \" percent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
